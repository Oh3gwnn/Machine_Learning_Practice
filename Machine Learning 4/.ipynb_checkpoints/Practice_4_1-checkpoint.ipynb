{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjVSKv3Jswjq"
   },
   "source": [
    "## **기본 설정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWnyE30kswjr"
   },
   "source": [
    "- 필수 모듈 불러오기\n",
    "- 그래프 출력 관련 기본 설정 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1sKJ_njswjr"
   },
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"training_linear_models\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# 어레이 데이터를 csv 파일로 저장하기\n",
    "def save_data(fileName, arrayName, header=''):\n",
    "    np.savetxt(fileName, arrayName, delimiter=',', header=header, comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y1hqAzoswlD"
   },
   "source": [
    "## **과제 1: 조기 종료 & 배치 경사 하강법 시그모이드 함수(사이킷런 미활용)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7bBVuMRswlD"
   },
   "source": [
    "조기 종료를 사용한 배치 경사 하강법으로 로지스틱 회귀를 구현하라.\n",
    "단, 사이킷런을 전혀 사용하지 않아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtpNoKKioBq-"
   },
   "source": [
    "__단계 1: 데이터 준비__ \n",
    "\n",
    "아래 코드는 이진 분류 설명을 위해 꽃잎 너비(petal width) 특성을 이용하여 버지니카 품종 여부를 판정하는 데에\n",
    "사용되는 데이터셋을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vy3vJalHldYl"
   },
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2, 3)]                  # 꽃잎 길이와 너비\n",
    "y = (iris[\"target\"] == 2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLGzSOr2ldYu"
   },
   "outputs": [],
   "source": [
    "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuaxQJVIldYu"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1235)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8MdT0-AldYu"
   },
   "source": [
    "__단계 2: 데이터셋 분할__ \n",
    "\n",
    "데이터셋을 훈련, 검증, 테스트 용도로 6대 2대 2의 비율로 무작위로 분할한다.\n",
    "\n",
    "- 훈련 세트: 60%\n",
    "- 검증 세트: 20%\n",
    "- 테스트 세트: 20%\n",
    "\n",
    "아래 코드는 사이킷런의 `train_test_split()` 함수를 사용하지 않고 \n",
    "수동으로 무작위 분할하는 방법을 보여준다.\n",
    "먼저 각 세트의 크기를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA947aG8ldYu"
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
    "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
    "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
    "\n",
    "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
    "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
    "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1XOEfN6ldYu"
   },
   "source": [
    "`np.random.permutation()` 함수를 이용하여 인덱스를 무작위로 섞는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkCJAWoRldYv"
   },
   "outputs": [],
   "source": [
    "rnd_indices = np.random.permutation(total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWLa4p2EldYv"
   },
   "source": [
    "인덱스가 무작위로 섞였기 때문에 무작위로 분할하는 효과를 얻는다.\n",
    "방법은 섞인 인덱스를 이용하여 지정된 6:2:2의 비율로 훈련, 검증, 테스트 세트로 분할하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my7vDBejldYv"
   },
   "outputs": [],
   "source": [
    "X_train = X_with_bias[rnd_indices[:train_size]]\n",
    "y_train = y[rnd_indices[:train_size]]\n",
    "\n",
    "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
    "y_valid = y[rnd_indices[train_size:-test_size]]\n",
    "\n",
    "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
    "y_test = y[rnd_indices[-test_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRqMkiESldYw"
   },
   "source": [
    "__단계 3: 타깃 변환__ \n",
    "\n",
    "타깃은 0, 1로 설정되어 있다. 차례대로 버지니카가 아닌 품종, 버지니카 품종을 가리킨다.\n",
    "훈련 세트의 첫 5개 샘플의 품종은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dr6-2jJCldYw",
    "outputId": "327b82a9-d2d4-4719-8aca-c16ac930aeb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 415,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aadh7u5OldYw"
   },
   "source": [
    "학습을 위해 타깃을 원-핫 벡터로 변환해야 한다. \n",
    "이유는 소프트맥스 회귀는 샘플이 주어지면 각 클래스별로 속할 확률을 구하고\n",
    "구해진 결과를 실제 확률과 함께 이용하여 비용함수를 계산하기 때문이다. \n",
    "\n",
    "붓꽃 데이터의 경우 세 개의 품종 클래스별로 속할 확률을 계산해야 하기 때문에 \n",
    "품종을 0, 1의 하나의 숫자로 두기 보다는 해당 클래스는 1, 나머지는 0인\n",
    "확률값으로 이루어진 어레이로 다루어야 소프트맥스 회귀가 계산한 클래스별 확률과 \n",
    "연결된다.\n",
    "\n",
    "아래 함수 `to_one_hot()` 함수는 길이가 m이면서 0, 1로 이루어진 1차원 어레이가 입력되면\n",
    "(m, 2) 모양의 원-핫 벡터를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Krdl0k1ZldYw"
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    n_classes = y.max() + 1                 # 클래스 수\n",
    "    m = len(y)                              # 샘플 수\n",
    "    Y_one_hot = np.zeros((m, n_classes))    # (샘플 수, 클래스 수) 0-벡터 생성\n",
    "    Y_one_hot[np.arange(m), y] = 1          # 샘플 별로 해당 클래스의 값만 1로 변경. (넘파이 인덱싱 활용)\n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyZEaItUldYx"
   },
   "source": [
    "샘플 5개에 대해 잘 작동하는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tcw5XP3pldYx",
    "outputId": "d07eb68f-8de6-414f-89fc-4b3e9c249869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 417,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY09ce6qldYx",
    "outputId": "dd623b0a-cde0-476d-db12-0b7295276b8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 418,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_one_hot(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5bJVsjhldYx"
   },
   "source": [
    "이제 훈련/검증/테스트 세트의 타깃을 모두 원-핫 벡터로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpi4x4Y3ldYy"
   },
   "outputs": [],
   "source": [
    "Y_train_one_hot = to_one_hot(y_train)\n",
    "Y_valid_one_hot = to_one_hot(y_valid)\n",
    "Y_test_one_hot = to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aio2g7TToFue"
   },
   "source": [
    "__단계 4: 로지스틱 회귀 시그모이드 함수__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NWYCJdRWkXv"
   },
   "outputs": [],
   "source": [
    "def sigmoid(logits):\n",
    "    return 1.0 / (1 + np.exp(-logits))  # 시그모이드 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvMSfvZ5ldYz"
   },
   "source": [
    "__단계 5: 경사하강법 활용 훈련__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToEjsNM7ldYz"
   },
   "source": [
    "경사하강법을 구현하기 위해 아래 비용함수와 비용함수의 그레이디언트를 파이썬으로 \n",
    "구현할 수 있어야 한다.\n",
    "\n",
    "- 비용 함수($K$는 클래스 수, $m$은 샘플 수):\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}\n",
    "$$\n",
    "\n",
    "위의 수식을 코드로 표현하면 다음과 같다.\n",
    "\n",
    "-np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))\n",
    "\n",
    "- 그레이디언트 공식(클래스 $k$에 대해):\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}\n",
    "$$\n",
    "\n",
    "__주의사항:__ \n",
    "수학적으로 $\\hat{p}_k^{(i)} = 0$이면 \n",
    "$\\log\\left(\\hat{p}_k^{(i)}\\right)$는 정의되지 않는다.\n",
    "`NaN` 값을 피하기 위해 \n",
    "$\\hat{p}_k^{(i)}$에 작은 값 `epsilon` 추가한다.\n",
    "여기서는 `1e-7`을 사용한다. \n",
    "사실 너무 작은 `epsilon`을 0에 더하면\n",
    "컴퓨터가 그래도 0으로 취급할 수 있음에 조심해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2gkruxQldY0"
   },
   "source": [
    "이제 훈련 코드를 작성할 수 있다.\n",
    "클래스별 파라미터로 이루어진 $(n+1, K)$ 행렬 모양의 2차원 넘파이 어레이 $\\Theta$를 \n",
    "생성하기 위해 $n$과 $K$를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQlASSjnldY0"
   },
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]           # 특성 수(n) + 1, 붓꽃의 경우: 특성 2개 + 1\n",
    "n_outputs = len(np.unique(y_train))   # 중복을 제거한 클래스 수(K), 붓꽃의 경우: 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq0bWBbtldY0"
   },
   "source": [
    "파라미터 $\\Theta$를 무작위로 초기 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snHxET_yldY0"
   },
   "outputs": [],
   "source": [
    "Theta = np.random.randn(n_inputs, n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwyOGm-XldY0"
   },
   "source": [
    "배치 경사하강법 훈련은 아래 코드를 통해 이루어진다.\n",
    "\n",
    "- `eta = 0.01`: 학습률\n",
    "- `n_iterations = 5001` : 에포크 수\n",
    "- `m = len(X_train)`: 훈련 세트 크기, 즉 훈련 샘플 수\n",
    "- `epsilon = 1e-7`: $\\log$ 값이 항상 계산되도록 더해지는 작은 실수\n",
    "- `logits`: 모든 샘플에 대한 클래스별 점수, 즉 $\\mathbf{X}_{\\textit{train}}\\, \\Theta$\n",
    "- `Y_proba`: 모든 샘플에 대해 계산된 클래스 별 소속 확률, 즉 $\\hat P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09pa8AH7ldY0",
    "outputId": "8041ae97-0a02-43b4-e16a-838aabb28bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 424.17283178098626\n",
      "1000 41.043384218852445\n",
      "2000 32.74074062063721\n",
      "3000 28.744312224357305\n",
      "4000 26.237295992550052\n",
      "5000 24.474139687325014\n",
      "6000 23.150000374030935\n",
      "7000 22.11153790859484\n",
      "8000 21.271448179525667\n",
      "9000 20.57570343517272\n",
      "10000 19.988786219677582\n",
      "11000 19.486246358338462\n",
      "12000 19.0506272909059\n",
      "13000 18.669090438381183\n",
      "14000 18.33195790344411\n",
      "15000 18.03178070374586\n",
      "16000 17.762722037185707\n",
      "17000 17.52013688117732\n",
      "18000 17.300278070184774\n",
      "19000 17.100086212554693\n",
      "20000 16.91703658618475\n"
     ]
    }
   ],
   "source": [
    "#  배치 경사하강법 구현\n",
    "eta = 0.1\n",
    "n_iterations = 20001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for iteration in range(n_iterations):     # 20001번 반복 훈련\n",
    "    logits = X_train.dot(Theta)\n",
    "    Y_proba = sigmoid(logits)\n",
    "    \n",
    "    if iteration % 1000 == 0:              # 1000 에포크마다 손실(비용) 계산해서 출력\n",
    "      loss = -np.mean(np.sum((Y_train_one_hot*np.log(Y_proba + epsilon) + (1-Y_train_one_hot)*np.log(1 - Y_proba + epsilon))))\n",
    "      print(iteration, loss)\n",
    "    \n",
    "    error = Y_proba - Y_train_one_hot     # 그레이디언트 계산.\n",
    "    gradients = 1/m * X_train.T.dot(error)\n",
    "    \n",
    "    Theta = Theta - eta * gradients       # 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO-mdlfqldY1"
   },
   "source": [
    "학습된 파라미터는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dsmhq1MldY1",
    "outputId": "b45ec0ff-dfb8-4b28-8084-365f4766060c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.42973906, -17.40609421],\n",
       "       [ -1.21742315,   1.20856212],\n",
       "       [ -6.93030596,   6.94259264]])"
      ]
     },
     "execution_count": 424,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8fST0MyldY1"
   },
   "source": [
    "검증 세트에 대한 예측과 정확도는 다음과 같다.\n",
    "`logits`, `Y_proba`를 검증 세트인 `X_valid`를 이용하여 계산한다.\n",
    "예측 클래스는 `Y_proba`에서 가장 큰 값을 갖는 인덱스로 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAxtCSkjldY1",
    "outputId": "a989eae6-8411-44ac-df6b-7408607b3fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 425,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_valid.dot(Theta)              \n",
    "Y_proba = sigmoid(logits)\n",
    "y_predict = np.argmax(Y_proba, axis=1)          # 가장 높은 확률을 갖는 클래스 선택\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_valid)  # 정확도 계산\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzerHBmYldY1"
   },
   "source": [
    "__단계 6: 규제가 추가된 경사하강법 활용 훈련__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyIZXA0vldY2"
   },
   "source": [
    "$\\ell_2$ 규제가 추가된 경사하강법 훈련을 구현한다. \n",
    "코드는 기본적으로 동일하다.\n",
    "다만 손실(비용)에 $\\ell_2$ 페널티가 추가되었고 \n",
    "그래디언트에도 항이 추가되었다(`Theta`의 첫 번째 원소는 편향이므로 규제하지 않습니다). \n",
    "\n",
    "- 학습률 `eta` 증가됨.\n",
    "- `alpha = 0.2`: 규제 강도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_VQ48UJldY2",
    "outputId": "d194c8f5-1283-4c60-81ba-e45af511a340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 487.6838219479042\n",
      "1000 56.90670055992519\n",
      "2000 54.189604938235796\n",
      "3000 53.70682558231622\n",
      "4000 53.609377773456686\n",
      "5000 53.58923113138052\n",
      "6000 53.58504554936091\n",
      "7000 53.58417508939525\n",
      "8000 53.58399402496207\n",
      "9000 53.5839563600891\n",
      "10000 53.58394852500216\n",
      "11000 53.58394689513592\n",
      "12000 53.58394655608864\n",
      "13000 53.58394648555954\n",
      "14000 53.58394647088794\n",
      "15000 53.58394646783594\n",
      "16000 53.58394646720106\n",
      "17000 53.58394646706902\n",
      "18000 53.58394646704159\n",
      "19000 53.583946467035844\n",
      "20000 53.583946467035844\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 20001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "alpha = 0.2       # 규제 하이퍼파라미터\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)  # 파라미터 새로 초기화\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    logits = X_train.dot(Theta)\n",
    "    Y_proba = sigmoid(logits)\n",
    "    \n",
    "    if iteration % 1000 == 0:\n",
    "        xentropy_loss = -np.mean(np.sum((Y_train_one_hot*np.log(Y_proba + epsilon) + (1-Y_train_one_hot)*np.log(1 - Y_proba + epsilon))))\n",
    "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))  # 편향은 규제에서 제외\n",
    "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
    "        print(iteration, loss)\n",
    "    \n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    l2_loss_gradients = np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]   # l2 규제 그레이디언트\n",
    "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
    "    \n",
    "    Theta = Theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvH3GwDvX10O",
    "outputId": "740c8992-f715-4928-b066-60a4eb3c6081"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.62124922, -4.62124922],\n",
       "       [-0.78010499,  0.78010499],\n",
       "       [-0.44256214,  0.44256214]])"
      ]
     },
     "execution_count": 427,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egQOtIgPldY2",
    "outputId": "6ae9d1c6-19a9-4f6a-ca23-52b5459130df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 428,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_valid.dot(Theta)\n",
    "Y_proba = sigmoid(logits)\n",
    "y_predict = np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_valid)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wu8YMP3ldY3"
   },
   "source": [
    "__단계 7: 조기 종료 추가__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zPNNj-IldY3"
   },
   "source": [
    "위 규제가 사용된 모델의 훈련 과정에서\n",
    "매 에포크마다 검증 세트에 대한 손실을 계산하여 오차가 줄어들다가 증가하기 시작할 때 멈추도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfGySMP9ldY3",
    "outputId": "f4d0d106-022b-4f54-ecce-ddb9001f5913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 158.16482495414078\n",
      "1000 21.78277529179991\n",
      "2000 20.85194273875507\n",
      "3000 20.68742353724357\n",
      "4000 20.65424689662067\n",
      "5000 20.64738916739576\n",
      "6000 20.645964490415082\n",
      "7000 20.645668208054406\n",
      "8000 20.64560657844655\n",
      "9000 20.645593758311257\n",
      "10000 20.64559109145327\n",
      "11000 20.645590536689596\n",
      "12000 20.645590421286787\n",
      "13000 20.64559039728052\n",
      "14000 20.645590392286696\n",
      "15000 20.64559039124788\n",
      "16000 20.64559039103179\n",
      "17000 20.645590390986843\n",
      "17332 20.645590390982044\n",
      "17333 20.645590390982044 조기 종료!\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 20001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "alpha = 0.2            # 규제 하이퍼파라미터\n",
    "best_loss = np.infty   # 최소 손실값 기억 변수\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)  # 파라미터 새로 초기화\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # 훈련 및 손실 계산\n",
    "    logits = X_train.dot(Theta)\n",
    "    Y_proba = sigmoid(logits)\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
    "    Theta = Theta - eta * gradients\n",
    "\n",
    "    # 검증 세트에 대한 손실 계산\n",
    "    logits = X_valid.dot(Theta)\n",
    "    Y_proba = sigmoid(logits)\n",
    "    xentropy_loss = -np.mean(np.sum((Y_valid_one_hot*np.log(Y_proba + epsilon) + (1-Y_valid_one_hot)*np.log(1 - Y_proba + epsilon))))\n",
    "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "    loss = xentropy_loss + alpha * l2_loss\n",
    "    \n",
    "    # 1000 에포크마다 검증 세트에 대한 손실 출력\n",
    "    if iteration % 1000 == 0:\n",
    "        print(iteration, loss)\n",
    "        \n",
    "    # 에포크마다 최소 손실값 업데이트\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
    "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
    "        print(iteration, loss, \"조기 종료!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDcTaahbX221",
    "outputId": "26c08727-4996-4773-bfa0-081b5a4e81ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.62124922, -4.62124922],\n",
       "       [-0.78010499,  0.78010499],\n",
       "       [-0.44256214,  0.44256214]])"
      ]
     },
     "execution_count": 430,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rl1sWhECldY3",
    "outputId": "19f78a29-ff18-4c67-ee03-7d426e2f3694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 431,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_valid.dot(Theta)\n",
    "Y_proba = sigmoid(logits)\n",
    "y_predict = np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_valid)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sTY1awdnyyW"
   },
   "source": [
    "예측 값이 처음에는 0.93에서 규제와 조기종료가 포함되고서 0.96으로 올라갔다.\n",
    "\n",
    "사실 시드 값에 따라 올라갔다가 떨어지다가 랜덤이지만, 데이터 값이 적어서 그런 것이라고 판단된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1NU9SXSldY5"
   },
   "source": [
    "## **과제 2: 과제 1 + 다중 클래스 분류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Riwt4ZCyldY6"
   },
   "source": [
    "과제 1에서 구현된 로지스틱 회귀 알고리즘에 일대다(OvR) 방식을 적용하여 붓꽃에 대한 다중 클래스 분류 알고리즘을 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qqun0BIFF_T"
   },
   "outputs": [],
   "source": [
    "np.random.seed(2042)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOo3tERZPgIW"
   },
   "source": [
    "데이터 전처리 def 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSfpc-L3FSrR"
   },
   "outputs": [],
   "source": [
    "def datasetting(X, y):\n",
    "  X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
    "\n",
    "  test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
    "  validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
    "  total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
    "\n",
    "  test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
    "  validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
    "  train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%\n",
    "  rnd_indices = np.random.permutation(total_size)\n",
    "\n",
    "  X_train = X_with_bias[rnd_indices[:train_size]]\n",
    "  y_train = y[rnd_indices[:train_size]]\n",
    "\n",
    "  X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
    "  y_valid = y[rnd_indices[train_size:-test_size]]\n",
    "\n",
    "  X_test = X_with_bias[rnd_indices[-test_size:]]\n",
    "  y_test = y[rnd_indices[-test_size:]]\n",
    "\n",
    "  Y_train_one_hot = to_one_hot(y_train)\n",
    "  Y_valid_one_hot = to_one_hot(y_valid)\n",
    "  Y_test_one_hot = to_one_hot(y_test)\n",
    "  \n",
    "  return X_train, y_train, X_valid, y_valid, X_test, y_test, Y_train_one_hot, Y_valid_one_hot, Y_test_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtXoUpHWPj8_"
   },
   "source": [
    "iris 데이터셋(붓꽃 데이터)가 50 단위로 나뉘는데, 각각 품종에 따른 Theta값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jake5xZQFF_C",
    "outputId": "613c3577-74bf-420a-cecf-4d17ed92876c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 70.66529783165817\n",
      "5 42.16963510195836\n",
      "6 42.21402352002106 조기 종료!\n",
      "0 39.746341342289384\n",
      "1000 21.585289185618613\n",
      "2000 20.819933833361397\n",
      "3000 20.68107137089968\n",
      "4000 20.652938156954345\n",
      "5000 20.647117463396086\n",
      "6000 20.645907993535097\n",
      "7000 20.645656456497843\n",
      "8000 20.645604133913228\n",
      "9000 20.64559324979751\n",
      "10000 20.64559098567153\n",
      "11000 20.64559051468471\n",
      "12000 20.645590416709297\n",
      "13000 20.645590396328316\n",
      "14000 20.645590392088625\n",
      "15000 20.64559039120667\n",
      "16000 20.64559039102322\n",
      "17000 20.645590390985063\n",
      "17442 20.645590390980036\n",
      "17443 20.645590390980036 조기 종료!\n",
      "0 238.9134259054118\n",
      "1000 21.7939936121296\n",
      "2000 20.853767525221155\n",
      "3000 20.687785823055552\n",
      "4000 20.654321544543702\n",
      "5000 20.647404665108493\n",
      "6000 20.6459677129491\n",
      "7000 20.64566887835367\n",
      "8000 20.64560671788077\n",
      "9000 20.64559378731647\n",
      "10000 20.645591097486967\n",
      "11000 20.645590537944727\n",
      "12000 20.64559042154789\n",
      "13000 20.645590397334846\n",
      "14000 20.645590392298008\n",
      "15000 20.645590391250217\n",
      "16000 20.64559039103228\n",
      "17000 20.645590390986946\n",
      "17452 20.6455903909809\n",
      "17453 20.6455903909809 조기 종료!\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "a = 50\n",
    "b = []\n",
    "\n",
    "while i < 150:\n",
    "  X = iris[\"data\"][i:a][:, (2, 3)]                  # 꽃잎 길이와 너비\n",
    "  y = iris[\"target\"][i:a]\n",
    "  datasetting(X, y)\n",
    "\n",
    "  n_inputs = X_train.shape[1]           # 특성 수(n) + 1, 붓꽃의 경우: 특성 2개 + 1\n",
    "  n_outputs = len(np.unique(y_train))   # 중복을 제거한 클래스 수(K), 붓꽃의 경우: 3개\n",
    "  Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "  eta = 0.1\n",
    "  n_iterations = 20001\n",
    "  m = len(X_train)\n",
    "  epsilon = 1e-7\n",
    "  alpha = 0.2            # 규제 하이퍼파라미터\n",
    "  best_loss = np.infty   # 최소 손실값 기억 변수\n",
    "\n",
    "  Theta = np.random.randn(n_inputs, n_outputs)  # 파라미터 새로 초기화\n",
    "\n",
    "  for iteration in range(n_iterations):\n",
    "      # 훈련 및 손실 계산\n",
    "      logits = X_train.dot(Theta)\n",
    "      Y_proba = sigmoid(logits)\n",
    "      error = Y_proba - Y_train_one_hot\n",
    "      gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
    "      Theta = Theta - eta * gradients\n",
    "      \n",
    "      # 검증 세트에 대한 손실 계산\n",
    "      logits = X_valid.dot(Theta)\n",
    "      Y_proba = sigmoid(logits)\n",
    "      xentropy_loss = -np.mean(np.sum((Y_valid_one_hot*np.log(Y_proba + epsilon) + (1-Y_valid_one_hot)*np.log(1 - Y_proba + epsilon))))\n",
    "      l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "      loss = xentropy_loss + alpha * l2_loss\n",
    "      \n",
    "      # 1000 에포크마다 검증 세트에 대한 손실 출력\n",
    "      if iteration % 1000 == 0:\n",
    "          print(iteration, loss)\n",
    "          \n",
    "      # 에포크마다 최소 손실값 업데이트\n",
    "      if loss < best_loss:\n",
    "          best_loss = loss\n",
    "      else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
    "          print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
    "          print(iteration, loss, \"조기 종료!\")\n",
    "          break\n",
    "  i += 50\n",
    "  a += 50\n",
    "  b.append(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNfyfylnPuI_"
   },
   "source": [
    "Theta 값들을 비교하여 best Theta 값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxCn0SlaIa9w"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "best_Y_proba = []\n",
    "\n",
    "while i < 3:\n",
    "  logits = X_valid.dot(b[i])\n",
    "  Y_proba = sigmoid(logits)\n",
    "  best_Y_proba.append(Y_proba)\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69c9tH0gMjqU"
   },
   "outputs": [],
   "source": [
    "w1 = best_Y_proba[0]\n",
    "w2 = best_Y_proba[1]\n",
    "w3 = best_Y_proba[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8_77druMzL7"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "w4 = np.zeros((30, 2))\n",
    "\n",
    "while i < len(w1):\n",
    "  if w1[i,0] > w2[i,0]:\n",
    "    w4[i,0] = w1[i,0]\n",
    "  else:\n",
    "    w4[i,0] = w2[i,0]\n",
    "  if w3[i,0] > w4[i,0]:\n",
    "    w4[i,0] = w3[i,0]\n",
    "\n",
    "  if w1[i,1] > w2[i,1]:\n",
    "    w4[i,1] = w1[i,1]\n",
    "  else:\n",
    "    w4[i,1] = w2[i,1]\n",
    "  if w3[i,1] > w4[i,1]:\n",
    "    w4[i,1] = w3[i,1]\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRImR1pD9P6H",
    "outputId": "9a42208a-5218-432e-d295-0c8d4b2e7a0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44549037, 0.59071592],\n",
       "       [0.4843735 , 0.52999988],\n",
       "       [0.47373974, 0.72676269],\n",
       "       [0.97331512, 0.45092582],\n",
       "       [0.96352836, 0.46241888],\n",
       "       [0.96651435, 0.4429628 ],\n",
       "       [0.96894927, 0.44561409],\n",
       "       [0.72715913, 0.45160281],\n",
       "       [0.52002264, 0.51119426],\n",
       "       [0.60990991, 0.48979979],\n",
       "       [0.51184044, 0.69200036],\n",
       "       [0.49471783, 0.50528217],\n",
       "       [0.51365403, 0.77622417],\n",
       "       [0.46807052, 0.70182271],\n",
       "       [0.57221952, 0.48443415],\n",
       "       [0.49187243, 0.66300607],\n",
       "       [0.60184996, 0.47731212],\n",
       "       [0.95579855, 0.46684456],\n",
       "       [0.60990991, 0.48979979],\n",
       "       [0.74034552, 0.47647189],\n",
       "       [0.47675975, 0.53839877],\n",
       "       [0.51752401, 0.71743112],\n",
       "       [0.5146217 , 0.76238249],\n",
       "       [0.48219483, 0.81104647],\n",
       "       [0.83262417, 0.47295427],\n",
       "       [0.48340606, 0.54937712],\n",
       "       [0.96505208, 0.45267276],\n",
       "       [0.96758975, 0.45533467],\n",
       "       [0.65874639, 0.46309857],\n",
       "       [0.66395405, 0.49785228]])"
      ]
     },
     "execution_count": 445,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJdTy6FQPzjx"
   },
   "source": [
    "가장 좋은 성능을 보이는 Theta 값을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf60bl6nPFtH",
    "outputId": "5f14d76c-4462-4b77-a868-37fd4f68e51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 444,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(w4, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_valid)\n",
    "accuracy_score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fjVSKv3Jswjq"
   ],
   "name": "Practice_4-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
